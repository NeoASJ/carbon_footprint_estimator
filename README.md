# ğŸŒ Product Emission Prediction Using Machine Learning

## ğŸš€ Project Overview
The project combined data from the UK Greenhouse Gas Conversion Factors (2025) ğŸ‡¬ğŸ‡§ and a Kaggle e-commerce dataset ğŸ›’ to create a synthetic dataset with product details and estimated carbon emissions. Data preprocessing in Python ğŸ involved cleaning, handling missing values, and creating new features like mass âš–ï¸ and emission factor ğŸŒ«ï¸.

This project aims to predict the emissions of various products using machine learning regression models based on their mass and emission factor features. The target variable includes small product-specific noise ğŸ”Š added to simulate measurement uncertainties or real-world variance.

## ğŸ“Š Data Description
- The dataset contains product-related features starting with prefixes `mass_` and `ef_`, representing weights âš–ï¸ and emission factors ğŸŒ«ï¸, respectively.
- The target variable `Total Emissions` is perturbed with controlled noise based on the product category for realism ğŸ”„.
- Products vary from electronics like "Air Conditioner" â„ï¸ and "Laptop" ğŸ’» to apparel like "Shirt" ğŸ‘• and "Sneakers" ğŸ‘Ÿ.

## ğŸ¤– Models Used
- Random Forest Regressor ğŸŒ²
- LightGBM Regressor ğŸ’¡
- CatBoost Regressor ğŸ±
- XGBoost Regressor âš¡

Each model is trained using limited hyperparameters to observe model behavior and comparative performance. The metric used for evaluation is the coefficient of determination \(R^2\) ğŸ“ˆ.

## ğŸ¯ Noise Addition Approach
Noise is added as a fraction (10%) of product-specific emission ranges randomly either positively or negatively to the target. This models real world data variability ğŸŒ.

## âš™ï¸ Installation
Install dependencies using pip:


## â–¶ï¸ How to Run
- Load the dataset `processed.csv` into the script.
- Run the script to train the models and generate a bar plot comparing the \(R^2\) scores ğŸ“Š.
- LightGBM model can be saved for future use ğŸ’¾.

## ğŸ“ˆ Results and Visualization
The script plots the \(R^2\) scores of all models for quick comparison and insights.

## ğŸš€ Future Work
- Hyperparameter tuning to optimize each model ğŸ›ï¸.
- Incorporation of additional features or different noise scaling ğŸ”§.
- Extending models to classification or time series if data permits â³.

## ğŸ“« Contact
For questions or collaborations, please reach out via email: your.email@example.com âœ‰ï¸
